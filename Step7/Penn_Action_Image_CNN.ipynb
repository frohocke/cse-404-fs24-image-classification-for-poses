{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb1b974b-3127-4310-a1de-608acc8647be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6d50516a-6113-4c7e-86ec-133ffce664a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map of all actions \n",
    "ACTION_MAP = {\n",
    "    'baseball_pitch': 0, 'baseball_swing': 1, 'bench_press': 2, 'bowl': 3,\n",
    "    'clean_and_jerk': 4, 'golf_swing': 5, 'jump_rope': 6, 'jumping_jacks': 7,\n",
    "    'pullup': 8, 'pushup': 9, 'situp': 10, 'squat': 11,\n",
    "    'strum_guitar': 12, 'tennis_forehand': 13, 'tennis_serve': 14\n",
    "}\n",
    "\n",
    "class PennActionDataset(Dataset):\n",
    "    def __init__(self, frames_dir, labels_dir, transform=None):\n",
    "        self.frames_dir = frames_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.frame_paths = []\n",
    "        self.action_labels = []\n",
    "        \n",
    "        image_sequence_folders = sorted(os.listdir(frames_dir))\n",
    "        \n",
    "        for seq_folder in image_sequence_folders:\n",
    "            if seq_folder != \".DS_Store\":\n",
    "                seq_frames_path = os.path.join(frames_dir, seq_folder)\n",
    "                \n",
    "                frames = sorted(os.listdir(seq_frames_path))\n",
    "                if frames[0] == \".DS_Store\":\n",
    "                    frames.remove(\".DS_Store\")\n",
    "\n",
    "                sampled_frames = frames[::40]\n",
    "                for frame in sampled_frames:\n",
    "                    frame_path = os.path.join(seq_frames_path, frame)\n",
    "                              \n",
    "                    self.frame_paths.append(frame_path)\n",
    "                \n",
    "                    label_path = os.path.join(labels_dir, seq_folder + '.mat')\n",
    "                    annotation = loadmat(label_path)\n",
    "                    action_label = annotation['action'][0]\n",
    "                    self.action_labels.append(ACTION_MAP[action_label])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.frame_paths[idx]\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = torch.tensor(self.action_labels[idx])\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "09ffb554-c6f6-4716-9551-20eedd5635ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensor \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet normalize\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "frames_dir = '/Users/jnehra/Desktop/ML/Penn_Action/frames'\n",
    "labels_dir = '/Users/jnehra/Desktop/ML/Penn_Action/labels'\n",
    "\n",
    "dataset = PennActionDataset(frames_dir, labels_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "219b1a1d-c433-4533-a26e-21ebbb41ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1) \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, 15) # 15 outputs \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Flatten\n",
    "        x = x.view(-1, 32 * 56 * 56)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Output layer\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6657ade0-021f-4854-ab8a-7998d318d43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Split dataset to train and test \n",
    "#train_size = int(0.8 * len(dataset))\n",
    "#test_size = len(dataset) - train_size\n",
    "#train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "#print(len(train_dataset))\n",
    "labels = [dataset.action_labels[i] for i in range(len(dataset))]\n",
    "\n",
    "# Stratified split\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(dataset)), \n",
    "    test_size=0.2, \n",
    "    stratify=labels, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create subsets\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9cf9c075-7f8f-42c8-b4ba-bc1674f4734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-entropy loss as the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608df1ef-6ca0-4b6e-8cf5-bf81ddd3b9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: Train Loss: 2.4410, Train Accuracy: 20.23%, Validation Loss: 2.1919, Validation Accuracy: 30.95%\n",
      "Epoch 2/15: Train Loss: 1.9496, Train Accuracy: 38.34%, Validation Loss: 1.9638, Validation Accuracy: 37.43%\n",
      "Epoch 3/15: Train Loss: 1.5034, Train Accuracy: 54.11%, Validation Loss: 1.5374, Validation Accuracy: 52.95%\n",
      "Epoch 4/15: Train Loss: 1.0647, Train Accuracy: 67.95%, Validation Loss: 1.3230, Validation Accuracy: 60.10%\n",
      "Epoch 5/15: Train Loss: 0.6599, Train Accuracy: 80.44%, Validation Loss: 0.9527, Validation Accuracy: 71.43%\n",
      "Epoch 6/15: Train Loss: 0.3342, Train Accuracy: 91.54%, Validation Loss: 0.9255, Validation Accuracy: 72.67%\n",
      "Epoch 7/15: Train Loss: 0.1749, Train Accuracy: 95.88%, Validation Loss: 0.7529, Validation Accuracy: 79.62%\n",
      "Epoch 8/15: Train Loss: 0.0955, Train Accuracy: 97.90%, Validation Loss: 0.8006, Validation Accuracy: 79.33%\n",
      "Epoch 9/15: Train Loss: 0.0620, Train Accuracy: 98.74%, Validation Loss: 0.7611, Validation Accuracy: 81.43%\n",
      "Epoch 10/15: Train Loss: 0.0419, Train Accuracy: 99.26%, Validation Loss: 0.8399, Validation Accuracy: 80.29%\n",
      "Epoch 11/15: Train Loss: 0.0347, Train Accuracy: 99.45%, Validation Loss: 0.7400, Validation Accuracy: 82.19%\n",
      "Epoch 12/15: Train Loss: 0.0323, Train Accuracy: 99.31%, Validation Loss: 0.8800, Validation Accuracy: 80.38%\n",
      "Epoch 13/15: Train Loss: 0.0203, Train Accuracy: 99.69%, Validation Loss: 0.7841, Validation Accuracy: 82.29%\n",
      "Epoch 14/15: Train Loss: 0.0109, Train Accuracy: 99.81%, Validation Loss: 0.8260, Validation Accuracy: 80.86%\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # training \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # backpropagation \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  # weight update \n",
    "    \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # testing \n",
    "    # Set model to eval mode \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    test_accuracies.append(100 * val_correct / val_total)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: \"\n",
    "          f\"Train Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {100 * correct/total:.2f}%, \"\n",
    "          f\"Validation Loss: {val_loss/len(test_loader):.4f}, Validation Accuracy: {100 * val_correct/val_total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb0d5a5-f4c7-4944-8cf5-dfde6935aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(epochs), train_losses, label='Train Loss', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(epochs), test_accuracies, label='Test Accuracy', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Accuracy')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdda1c4-f960-47b3-a283-72704f8a6da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
